{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92954921",
      "metadata": {
        "id": "92954921"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "debc4873",
      "metadata": {
        "id": "debc4873"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, clear_output\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3bb1736a",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = \"/home/lis/Utkov/TEMP/DATA\"\n",
        "\n",
        "interactions_df = pd.read_csv(os.path.join(DATA_PATH, 'interactions.csv'))\n",
        "users_df = pd.read_csv(os.path.join(DATA_PATH, 'users.csv'))\n",
        "items_df = pd.read_csv(os.path.join(DATA_PATH, 'items.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "85049f14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "85049f14",
        "outputId": "bbe00e3e-6002-42be-b343-8ce0d9f957a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>last_watch_dt</th>\n",
              "      <th>total_dur</th>\n",
              "      <th>watched_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>176549</td>\n",
              "      <td>9506</td>\n",
              "      <td>2021-05-11</td>\n",
              "      <td>4250</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>699317</td>\n",
              "      <td>1659</td>\n",
              "      <td>2021-05-29</td>\n",
              "      <td>8317</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>656683</td>\n",
              "      <td>7107</td>\n",
              "      <td>2021-05-09</td>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>864613</td>\n",
              "      <td>7638</td>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>14483</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>964868</td>\n",
              "      <td>9506</td>\n",
              "      <td>2021-04-30</td>\n",
              "      <td>6725</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
              "0   176549     9506    2021-05-11       4250         72.0\n",
              "1   699317     1659    2021-05-29       8317        100.0\n",
              "2   656683     7107    2021-05-09         10          0.0\n",
              "3   864613     7638    2021-07-05      14483        100.0\n",
              "4   964868     9506    2021-04-30       6725        100.0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0fbac8ce",
      "metadata": {
        "id": "0fbac8ce"
      },
      "outputs": [],
      "source": [
        "interactions_df = interactions_df[interactions_df['last_watch_dt'] < '2021-04-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "efe98dde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efe98dde",
        "outputId": "78eabb80-35c1-41ef-c11d-06f672cce24c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(263874, 5)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interactions_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "78342a0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78342a0b",
        "outputId": "f7a6bf12-c05d-4501-d66b-9ba011e1e050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# users: 86614\n",
            "# users with at least 5 interactions: 14563\n"
          ]
        }
      ],
      "source": [
        "# оставляем пользователей, у которых есть хотя бы 5 интеракций\n",
        "users_interactions_count_df = interactions_df.groupby(['user_id', 'item_id']).size().groupby('user_id').size()\n",
        "print('# users: %d' % len(users_interactions_count_df))\n",
        "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['user_id']]\n",
        "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0bd0d31d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bd0d31d",
        "outputId": "de5df52a-0746-4278-8715-3a218bf9becc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of interactions: 263874\n",
            "# of interactions from users with at least 5 interactions: 142670\n"
          ]
        }
      ],
      "source": [
        "print('# of interactions: %d' % len(interactions_df))\n",
        "interactions_from_selected_users_df = interactions_df.merge(users_with_enough_interactions_df,\n",
        "               how = 'right',\n",
        "               left_on = 'user_id',\n",
        "               right_on = 'user_id')\n",
        "print('# of interactions from users with at least 5 interactions: %d' % len(interactions_from_selected_users_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2df43577",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "2df43577",
        "outputId": "6b63ca61-7a40-4dac-e4c6-7fe5b1abb220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of unique user/item interactions: 142670\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>watched_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>849</td>\n",
              "      <td>6.375039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>4345</td>\n",
              "      <td>6.658211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>10283</td>\n",
              "      <td>6.658211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>12261</td>\n",
              "      <td>6.658211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>15997</td>\n",
              "      <td>6.658211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>32</td>\n",
              "      <td>952</td>\n",
              "      <td>6.044394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>32</td>\n",
              "      <td>4382</td>\n",
              "      <td>4.954196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>32</td>\n",
              "      <td>4807</td>\n",
              "      <td>6.658211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>32</td>\n",
              "      <td>10436</td>\n",
              "      <td>6.658211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>32</td>\n",
              "      <td>12132</td>\n",
              "      <td>6.658211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id  watched_pct\n",
              "0       21      849     6.375039\n",
              "1       21     4345     6.658211\n",
              "2       21    10283     6.658211\n",
              "3       21    12261     6.658211\n",
              "4       21    15997     6.658211\n",
              "5       32      952     6.044394\n",
              "6       32     4382     4.954196\n",
              "7       32     4807     6.658211\n",
              "8       32    10436     6.658211\n",
              "9       32    12132     6.658211"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def smooth_user_preference(x):\n",
        "    return math.log(1+x, 2)\n",
        "\n",
        "interactions_full_df = interactions_from_selected_users_df \\\n",
        "                    .groupby(['user_id', 'item_id'])['watched_pct'].sum() \\\n",
        "                    .apply(smooth_user_preference).reset_index()\n",
        "print('# of unique user/item interactions: %d' % len(interactions_full_df))\n",
        "interactions_full_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "039e1442",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "039e1442",
        "outputId": "4aff793b-7466-4f4d-c30b-1ef4969c44d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# interactions on Train set: 114136\n",
            "# interactions on Test set: 28534\n"
          ]
        }
      ],
      "source": [
        "interactions_train_df, interactions_test_df = train_test_split(interactions_full_df,\n",
        "                                   stratify=interactions_full_df['user_id'],\n",
        "                                   test_size=0.20,\n",
        "                                   random_state=42)\n",
        "\n",
        "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
        "print('# interactions on Test set: %d' % len(interactions_test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0b38dea2",
      "metadata": {
        "id": "0b38dea2"
      },
      "outputs": [],
      "source": [
        "#Indexing by personId to speed up the searches during evaluation\n",
        "interactions_full_indexed_df = interactions_full_df.set_index('user_id')\n",
        "interactions_train_indexed_df = interactions_train_df.set_index('user_id')\n",
        "interactions_test_indexed_df = interactions_test_df.set_index('user_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bbb9a04d",
      "metadata": {
        "id": "bbb9a04d"
      },
      "outputs": [],
      "source": [
        "def get_items_interacted(person_id, interactions_df):\n",
        "    # Get the user's data and merge in the movie information.\n",
        "    interacted_items = interactions_df.loc[person_id]['item_id']\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4c56b58f",
      "metadata": {
        "id": "4c56b58f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, clear_output\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9039ffb8",
      "metadata": {
        "id": "9039ffb8"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "SEED = 42 # random seed for reproducibility\n",
        "LR = 1e-3 # learning rate, controls the speed of the training\n",
        "WEIGHT_DECAY = 0.01 # lambda for L2 reg. ()\n",
        "NUM_EPOCHS = 200 # num training epochs (how many times each instance will be processed)\n",
        "GAMMA = 0.9995 # learning rate scheduler parameter\n",
        "BATCH_SIZE = 9000 # training batch size\n",
        "EVAL_BATCH_SIZE = 3000 # evaluation batch size.\n",
        "DEVICE = 'cuda:2' #'cuda' # device to make the calculations on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b47f52ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b47f52ce",
        "outputId": "78d6a313-5af8-45d9-be8c-1e3fcc9c79b9"
      },
      "outputs": [],
      "source": [
        "total_df =  pd.concat([interactions_train_df, interactions_test_indexed_df.reset_index()])\n",
        "total_df['user_id'], users_keys = total_df.user_id.factorize()\n",
        "total_df['item_id'], items_keys = total_df.item_id.factorize()\n",
        "\n",
        "train_encoded = total_df.iloc[:len(interactions_train_df)].values\n",
        "test_encoded = total_df.iloc[len(interactions_train_df):].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "27e538cd",
      "metadata": {
        "id": "27e538cd"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "shape = [int(total_df['user_id'].max()+1), int(total_df['item_id'].max()+1)]\n",
        "X_train = csr_matrix((train_encoded[:, 2], (train_encoded[:, 0], train_encoded[:, 1])), shape=shape).toarray()\n",
        "X_test = csr_matrix((test_encoded[:, 2], (test_encoded[:, 0], test_encoded[:, 1])), shape=shape).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "89cc28b3",
      "metadata": {
        "id": "89cc28b3"
      },
      "outputs": [],
      "source": [
        "# Initialize the DataObject, which must return an element (features vector x and target value y)\n",
        "# for a given idx. This class must also have a length atribute\n",
        "class UserOrientedDataset(Dataset):\n",
        "    def __init__(self, X):\n",
        "        super().__init__() # to initialize the parent class\n",
        "        self.X = X.astype(np.float32)\n",
        "        self.len = len(X)\n",
        "\n",
        "    def __len__(self): # We use __func__ for implementing in-built python functions\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0ee1dfe3",
      "metadata": {
        "id": "0ee1dfe3"
      },
      "outputs": [],
      "source": [
        "# Initialize DataLoaders - objects, which sample instances from DataObject-s\n",
        "train_dl = DataLoader(\n",
        "    UserOrientedDataset(X_train),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "test_dl = DataLoader(\n",
        "    UserOrientedDataset(X_test),\n",
        "    batch_size = EVAL_BATCH_SIZE,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "dls = {'train': train_dl, 'test': test_dl}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Kzb-r7QxHArd",
      "metadata": {
        "id": "Kzb-r7QxHArd"
      },
      "source": [
        "Для того что бы побить бейзлайн, попробуем использовать вариационный автоэнкодер и докинуть больше слоев"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11b4e83",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim=8287, device='cuda:0'):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        \n",
        "        # latent mean and variance \n",
        "        self.mean_layer = nn.Linear(64, 2)\n",
        "        self.logvar_layer = nn.Linear(64, 2)\n",
        "        \n",
        "        # decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(2, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, input_dim)\n",
        "        )\n",
        "     \n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterization(self, mean, var):\n",
        "        epsilon = torch.randn_like(var).to(self.device)      \n",
        "        z = mean + var*epsilon\n",
        "        return z\n",
        "\n",
        "    def decode(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterization(mean, logvar)\n",
        "        x_hat = self.decode(z)\n",
        "        return x_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2c95f9af",
      "metadata": {
        "id": "2c95f9af"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(SEED) # Fix random seed to have reproducible weights of model layers\n",
        "\n",
        "model = Model()\n",
        "model.to(DEVICE)\n",
        "\n",
        "# Initialize GD method, which will update the weights of the model\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "# Initialize learning rate scheduler, which will decrease LR according to some rule\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
        "\n",
        "def rmse_for_sparse(x_pred, x_true):\n",
        "    mask = (x_true > 0)\n",
        "    sq_diff = (x_pred * mask - x_true) ** 2\n",
        "    mse = sq_diff.sum() / mask.sum()\n",
        "    return mse ** (1/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e9cdaf94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "e9cdaf94",
        "outputId": "c887662f-f5bd-4d21-b997-281a729d7267"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "lowest_loss_value = np.inf\n",
        "metrics_dict = {\n",
        "    \"Epoch\": [],\n",
        "    \"Train RMSE\": [],\n",
        "    \"Test RMSE\": [],\n",
        "}\n",
        "\n",
        "# Train loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    metrics_dict[\"Epoch\"].append(epoch)\n",
        "    for stage in ['train', 'test']:\n",
        "        with torch.set_grad_enabled(stage == 'train'): # Whether to start building a graph for a backward pass\n",
        "            if stage == 'train':\n",
        "                model.train() # Enable some \"special\" layers (will speak about later)\n",
        "            else:\n",
        "                model.eval() # Disable some \"special\" layers (will speak about later)\n",
        "\n",
        "            loss_at_stage = 0\n",
        "            for batch in dls[stage]:\n",
        "                batch = batch.to(DEVICE)\n",
        "                x_pred = model(batch) # forward pass: model(x_batch) -> calls forward()\n",
        "                loss = rmse_for_sparse(x_pred, batch) # ¡Important! y_pred is always the first arg\n",
        "                if stage == \"train\":\n",
        "                    loss.backward() # Calculate the gradients of all the parameters wrt loss\n",
        "                    optimizer.step() # Update the parameters\n",
        "                    scheduler.step()\n",
        "                    optimizer.zero_grad() # Zero the saved gradient\n",
        "                loss_at_stage += loss.item() * len(batch)\n",
        "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1/2)\n",
        "            \n",
        "            if rmse_at_stage < lowest_loss_value:\n",
        "                lowest_loss_value = rmse_at_stage\n",
        "                torch.save(model.state_dict(), 'best_autoencoder.pt')\n",
        "\n",
        "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
        "\n",
        "    if (epoch == NUM_EPOCHS - 1) or epoch % 10 == 9:\n",
        "        clear_output(wait=True)\n",
        "        display(pd.DataFrame(metrics_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9bf9546",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9bf9546",
        "outputId": "3a9c3571-c446-4604-c1c8-704356faa7e9"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "    X_pred = model(torch.Tensor(X_test).to(DEVICE))\n",
        "X_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3bca32fb",
      "metadata": {
        "id": "3bca32fb"
      },
      "outputs": [],
      "source": [
        "class AERecommender:\n",
        "    MODEL_NAME = 'Autoencoder'\n",
        "\n",
        "    def __init__(self, X_preds, X_train_and_val, X_test):\n",
        "\n",
        "        self.X_preds = X_preds.cpu().detach().numpy()\n",
        "        self.X_train_and_val = X_train_and_val\n",
        "        self.X_test = X_test\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_select_idx, topn=10, verbose=False):\n",
        "        user_preds = self.X_preds[user_id][items_to_select_idx]\n",
        "        items_idx = items_to_select_idx[np.argsort(-user_preds)[:topn]]\n",
        "\n",
        "        # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
        "        return items_idx\n",
        "\n",
        "    def evaluate(self, size=100):\n",
        "\n",
        "        X_total = self.X_train_and_val + self.X_test\n",
        "\n",
        "        true_5 = []\n",
        "        true_10 = []\n",
        "\n",
        "        for user_id in range(len(X_test)):\n",
        "            non_zero = np.argwhere(self.X_test[user_id] > 0).ravel()\n",
        "            all_nonzero = np.argwhere(X_total[user_id] > 0).ravel()\n",
        "            select_from = np.setdiff1d(np.arange(X_total.shape[1]), all_nonzero)\n",
        "\n",
        "            for non_zero_idx in non_zero:\n",
        "                random_non_interacted_100_items = np.random.choice(select_from, size=20, replace=False)\n",
        "                preds = self.recommend_items(user_id, np.append(random_non_interacted_100_items, non_zero_idx), topn=10)\n",
        "                true_5.append(non_zero_idx in preds[:5])\n",
        "                true_10.append(non_zero_idx in preds)\n",
        "\n",
        "        return {\"recall@5\": np.mean(true_5), \"recall@10\": np.mean(true_10)}\n",
        "\n",
        "ae_recommender_model = AERecommender(X_pred, X_train, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "4d846334",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d846334",
        "outputId": "14f8bfe8-8ba8-4a28-9f59-8bc57328f321"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'recall@5': 0.24413195900416396, 'recall@10': 0.49924424897851716}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ae_global_metrics = ae_recommender_model.evaluate()\n",
        "ae_global_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1V8GkFSXwsCU",
      "metadata": {
        "id": "1V8GkFSXwsCU"
      },
      "source": [
        "Будем считать предсказния для каждого юзера. Для этого нам нужна матрица взаимодействий, ее сохраним отдельно"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "7hhEyT6dwu8t",
      "metadata": {
        "id": "7hhEyT6dwu8t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14563, 8287)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_encoded = total_df.values\n",
        "shape = [int(total_df[\"user_id\"].max() + 1), int(total_df[\"item_id\"].max() + 1)]\n",
        "interactions_matrix = csr_matrix((full_encoded[:, 2],\n",
        "                                  (full_encoded[:, 0],full_encoded[:, 1])),\n",
        "                                 shape=shape).toarray()\n",
        "np.save('interactions_matrix.npy', interactions_matrix)\n",
        "interactions_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9acd644",
      "metadata": {},
      "source": [
        "Для большей скорости сохраним модель в torchscript, так она на 30% быстрее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ae5ee142",
      "metadata": {},
      "outputs": [],
      "source": [
        "traced_gpu = torch.jit.trace(model, torch.Tensor(interactions_matrix[42][np.newaxis, :]).to(DEVICE))\n",
        "torch.jit.save(traced_gpu, \"autoencoder.torchscript\")\n",
        "\n",
        "# сразу проверим\n",
        "model = torch.jit.load(\"autoencoder.torchscript\", map_location=DEVICE) # такая загрузка предпочтительнее\n",
        "with torch.inference_mode():\n",
        "    a = model(torch.Tensor(interactions_matrix[13][np.newaxis, :]).to(DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "01dcf660",
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoencoderModel():\n",
        "    def __init__(self, model_path, interactions_path, device='cuda:2'):\n",
        "        self.model = torch.jit.load(model_path, map_location=device)\n",
        "        self.interactions_matrix = np.load(interactions_path)\n",
        "        self.interactions_matrix_torch = torch.Tensor(self.interactions_matrix).to(device)\n",
        "        \n",
        "    def recommend_single(self, user_id, n_random_items=35, n_recos=10):\n",
        "        input = torch.unsqueeze(self.interactions_matrix_torch[user_id], 0)\n",
        "        with torch.inference_mode():\n",
        "            output = self.model(input)\n",
        "        output = output.numpy(force=True)\n",
        "        \n",
        "        already_watched = np.argwhere(self.interactions_matrix[user_id] > 0).ravel() # айтемы, где у нас не нулевое значение\n",
        "        non_interacted_all = np.setdiff1d(np.arange(self.interactions_matrix[user_id].shape[0]),\n",
        "                                          already_watched) # set(all_items) - set(already_watched)\n",
        "        non_interacted_random_items = np.random.choice(non_interacted_all,\n",
        "                                                       size=n_random_items,\n",
        "                                                       replace=False)\n",
        "        user_preds = output[0][non_interacted_random_items]\n",
        "        items_idx = non_interacted_random_items[np.argsort(-user_preds)[:n_recos]]\n",
        "\n",
        "        return items_idx\n",
        "    \n",
        "a = AutoencoderModel('autoencoder.torchscript', 'interactions_matrix.npy')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "reco_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
